<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>小wing的驿站</title>
    <link>https://xiaowing.github.io/tags/c/index.xml</link>
    <description>Recent content on 小wing的驿站</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>&amp;copy; Licensed under CC BY-NC-SA.</copyright>
    <atom:link href="https://xiaowing.github.io/tags/c/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>记一次面向线程栈的防爆栈机制的实现探索</title>
      <link>https://xiaowing.github.io/post/20180313_thread_stack_overflow_protection/</link>
      <pubDate>Tue, 13 Mar 2018 22:37:10 +0800</pubDate>
      
      <guid>https://xiaowing.github.io/post/20180313_thread_stack_overflow_protection/</guid>
      <description>&lt;p&gt;爆栈(&lt;a href=&#34;https://en.wikipedia.org/wiki/Stack_overflow&#34;&gt;&lt;em&gt;stack overflow&lt;/em&gt;&lt;/a&gt;), 众所周知是一种软件的致命错误, 一旦发生程序就core了。根据维基百科的描述，当代码中有以下三种情形时会引发爆栈&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;无限递归&lt;/li&gt;
&lt;li&gt;函数调用链展开过深&lt;/li&gt;
&lt;li&gt;函数内申请过大的局部变量&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;其中1.和2.本质上是相同的，不管是否递归，只要函数调用链过深，压栈过多就会引发爆栈。只不过在实践中，由递归更容易引发爆栈。&lt;/p&gt;

&lt;p&gt;可是在很多时候，我们无法避免递归。比如数据库在对SQL语句的执行实现中，伴随着输入的SQL语句的复杂性，间接递归通常是可以预见的。但是无论哪种情况，我们都不能容忍一个用户输入导致程序爆栈，因此这种情况下，我们就需要一个防爆栈机制&lt;/p&gt;

&lt;p&gt;下文通过介绍我经手的一个防爆栈机制的实现过程，分享一下有关程序设计的教训与心得:&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;背景目标&#34;&gt;背景目标&lt;/h2&gt;

&lt;p&gt;我们的系统是一个高并发的系统，实现的是基于线程的并发(session-per-thread模式)，由于用户输入可能会引发我们系统内部的合理的间接递归。由于用户输入的复杂性不可避免，如果极端情况下用户输入引发了一个会话爆栈，将会使整个进程core掉。因此我们需要一个基于线程栈的防爆栈机制。&lt;/p&gt;

&lt;p&gt;此外，为了尽可能地容忍更大地并发量，系统为每个用户会话创建后台线程时限定了线程栈的大小为&lt;strong&gt;256KB&lt;/strong&gt;(通过&lt;code&gt;pthread_attr_setstacksize()&lt;/code&gt;设置)&lt;/p&gt;

&lt;h2 id=&#34;借鉴-postgresql的防爆栈实现&#34;&gt;借鉴——PostgreSQL的防爆栈实现&lt;/h2&gt;

&lt;p&gt;首先我们想到了PG的实现，PG代码中也实现了一个防爆栈机制。其原理简要说明如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;PG在为新的用户会话创建后台进程(PG是session-per-process模式)后,在入口函数&lt;code&gt;PostmasterMain()&lt;/code&gt;中获取进程栈中的基地址,并将其记录在&lt;code&gt;postgres&lt;/code&gt;进程的一个全局变量(会话内可见)上&lt;/p&gt;

&lt;p&gt;&lt;em&gt;保存栈基址的代码如下:&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;pg_stack_base_t
set_stack_base(void)
{
    char stack_base;
    pg_stack_base_t old;

#if defined(__ia64__) || defined(__ia64)
    old.stack_base_ptr = stack_base_ptr;
    old.register_stack_base_ptr = register_stack_base_ptr;
#else
    old = stack_base_ptr;
#endif

    /* Set up reference point for stack depth checking */
    stack_base_ptr = &amp;amp;stack_base;  /* ★stack_base_ptr即为保存栈基址的全局变量 */
#if defined(__ia64__) || defined(__ia64)
    register_stack_base_ptr = ia64_get_bsp();
#endif

    return old;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;在SQL语句的处理逻辑在所有涉嫌递归调用的入口执行栈深的检查函数，通过比较检查时点所用的局部变量的地址与先前记录的栈基址做比较，如果差值超过&lt;strong&gt;阈值&lt;/strong&gt;，则退出当前SQL的执行并提示错误信息&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;PG中栈深的阈值(&lt;code&gt;max_stack_depth_bytes&lt;/code&gt;)默认为&lt;strong&gt;2MB&lt;/strong&gt;, 其大小可由用户配置，但最大值不能超过操作系统的栈大小(可通过&lt;code&gt;ulimit -a&lt;/code&gt;查询) &lt;strong&gt;减去 512KB&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;其比较栈深的代码实现如下:&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;/* src/backend/tcop/postgres.c */
bool
stack_is_too_deep(void)
{
    char        stack_top_loc;
    long        stack_depth;

    stack_depth = (long) (stack_base_ptr - &amp;amp;stack_top_loc);  /* ★stack_base_ptr即为保存栈基址的全局变量 */

    if (stack_depth &amp;lt; 0)
        stack_depth = -stack_depth;

    if (stack_depth &amp;gt; max_stack_depth_bytes &amp;amp;&amp;amp;
        stack_base_ptr != NULL)
        return true;


#if defined(__ia64__) || defined(__ia64)
    stack_depth = (long) (ia64_get_bsp() - register_stack_base_ptr);

    if (stack_depth &amp;gt; max_stack_depth_bytes &amp;amp;&amp;amp;
        register_stack_base_ptr != NULL)
        return true;
#endif   /* IA64 */

    return false;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;PG的代码质量是值得信赖的，所以我们借鉴了上述机制。由于两个系统的会话模型不同，因此我们做了一些改造: 由于我们系统的用户会话和线程是一一对应的关系，所以把栈基址的保存位置从全局变量放到了会话上下文中。比如上述检查栈深的代码就变成了类似以下的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;bool
stack_is_too_deep(session_t *session)
{
    char		stack_top_loc;
    long		stack_depth;

    stack_depth = (long) (session-&amp;gt;stack_base_ptr - &amp;amp;stack_top_loc);  /* 之前获取的栈基地址放在了会话上下文 */

    if (stack_depth &amp;lt; 0)
        stack_depth = -stack_depth;

    /* MAX_STACK_SIZE为256KB */
    if (stack_depth &amp;gt; MAX_STACK_SIZE &amp;amp;&amp;amp; stack_base_ptr != NULL)
        return true;

    return false;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;本以为这样一来就大功告成了，后来的事实证明： &lt;strong&gt;我们把问题考虑得太简单了&amp;hellip;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;第一次爆栈&#34;&gt;第一次爆栈&lt;/h2&gt;

&lt;p&gt;在事先了上述防爆栈机制后，为了测试效果，我们构造了一个会引发无限递归的用户输入, 希望将之加入回归测试集作为该防爆栈功能的看护用例。可是，当我们运行该用例时，结果却让我们傻眼了——&lt;strong&gt;程序直接core掉了&lt;/strong&gt;！！&lt;/p&gt;

&lt;p&gt;连忙分析生成的core文件:发现事发现场的线程栈有 &lt;strong&gt;3000+&lt;/strong&gt; 个栈帧(&lt;a href=&#34;https://en.wikipedia.org/wiki/Call_stack#STACK-FRAME&#34;&gt;stack frame&lt;/a&gt;), 最后程序core掉时所处的栈帧居然是标准库函数 &lt;code&gt;snprintf()&lt;/code&gt;&amp;hellip;&amp;hellip;换言之，&lt;strong&gt;防爆栈机制没有生效&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;原因分析&#34;&gt;原因分析&lt;/h3&gt;

&lt;p&gt;首先分析了一下PG原有的防爆栈实现，突然被其GUC参数&lt;code&gt;max_stack_depth_bytes&lt;/code&gt;的配置逻辑所吸引:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;栈深的阈值(&lt;code&gt;max_stack_depth_bytes&lt;/code&gt;)默认为&lt;strong&gt;2MB&lt;/strong&gt;, 其大小可由用户配置，但最大值不能超过操作系统的栈大小(可通过&lt;code&gt;ulimit -a&lt;/code&gt;查询) &lt;strong&gt;减去 512KB&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;PG的允许用户设置的阈值为什么不是直接等于操作系统的栈大小?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这是因为如果将阈值等于OS的栈大小，将会产生下述后果:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;只要程序走到栈深检查函数时，则说明栈深肯定没有超过阈值; 另一方面, 当栈深超过阈值时, 已经没有时间让程序在走到栈深检查函数去自我预警了.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;换言之: 关于栈深检查的阈值，应当设置为一个在两次检查之间事实上允许程序栈深适当超过的值。也就是说，在栈深的阈值和操作系统所允许的最大栈深之间应该放一个余量，这个余量要能够让程序在两次栈深检查之间继续展开栈帧并坚持到下一个栈深检查为止。——考虑到当代Linux系统下默认的栈大小为8MB，所以结合PG的&lt;code&gt;max_stack_depth_bytes&lt;/code&gt;的规格来看，PG所放的余量最大为6MB，最小也有512KB.&lt;/p&gt;

&lt;p&gt;但是在我们的实现中，我们将栈深检查的阈值直接定为线程栈的大小。这就意味着，我们为两次栈深检查之间没有放任何余量。这便使得栈深检查机制变得毫无意义。&lt;/p&gt;

&lt;p&gt;下图示意了这一次爆栈的原因:&lt;/p&gt;



&lt;div class=&#34;pure-g&#34;&gt;

  
  
  
  
  &lt;div class=&#34;pure-u-1-1&#34;&gt;
    &lt;div style=&#34;padding: 0 .2em&#34;&gt;
      &lt;img
        class=&#34;pure-img-responsive&#34;
        src=&#34;https://xiaowing.github.io/img/post/20180313/1st_bursting.png&#34;
        alt=&#34;第一次爆栈的原因&#34;&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  

&lt;/div&gt;


&lt;h3 id=&#34;第一次修正&#34;&gt;第一次修正&lt;/h3&gt;

&lt;p&gt;既然明白了原因，修正方法就很简单: 给阈值放点余量。经过反复试验，最终决定将这个余量设置为16KB。因此栈深检查的代码就修改为下述形式:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;bool
stack_is_too_deep(session_t *session)
{
    char		stack_top_loc;
    long		stack_depth;

    stack_depth = (long) (session-&amp;gt;stack_base_ptr - &amp;amp;stack_top_loc);  /* 之前获取的栈基地址放在了会话上下文 */

    if (stack_depth &amp;lt; 0)
        stack_depth = -stack_depth;

    /* MAX_STACK_SIZE为256KB */
    /* 检查的阈值为 (线程栈长度 - 16KB) */
    if (stack_depth &amp;gt; (MAX_STACK_SIZE - (16 * 1024)) &amp;amp;&amp;amp; 
        stack_base_ptr != NULL)
        return true;

    return false;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当然, 上述修改还是存在一些风险的: 毕竟余量16KB还是比较小的。如果两次栈深检查之间的函数展开中有某个函数使用了16KB的局部变量，照样会让程序爆栈core掉。为此，我又对代码进行了审视，确保了栈深检查之间的函数调用没有使用太多局部变量。之后，便将上述修正给commit了.&lt;/p&gt;

&lt;h2 id=&#34;第二次爆栈&#34;&gt;第二次爆栈&lt;/h2&gt;

&lt;p&gt;之后相当长的一段时间内，这个爆栈防护运行得都比较好。且放入回归测试集中的看护测试也总是能如期报出&amp;rdquo;&lt;strong&gt;stack too deep&lt;/strong&gt;&amp;ldquo;的错误消息。一切看上去相安无事.&lt;/p&gt;

&lt;p&gt;然而，距离上一次对&lt;code&gt;stack_is_too_deep()&lt;/code&gt;的修正已有两个月的某一天下午，回归测试被运行起来后，上述的看护测试没有再能如期报出&amp;rdquo;&lt;strong&gt;stack too deep&lt;/strong&gt;&amp;ldquo;的错误消息, 而是直接导致了程序core了。再一分析core文件的栈信息，发现有&lt;strong&gt;1000+个&lt;/strong&gt;栈帧——显然，又爆栈了&amp;hellip;&lt;/p&gt;

&lt;p&gt;得知这一信息后，我的内心是纠结的：理论上可以考虑把之前修正中引入的余量再放大，把检查的阈值再降低; 但是这样一来，将有可能会导致&lt;code&gt;stack_is_too_deep()&lt;/code&gt;错误消息报出的频率增大，进而导致我们规格中定义的用户线程栈的默认大小256KB失去意义. 如果再贸然增大线程栈的默认大小，那么就有可能会导致并发度的下降，进而产生一连串连锁反应。更何况，就算要放大余量，放到多少为合适呢?&amp;hellip;&amp;hellip;&lt;/p&gt;

&lt;p&gt;思来想去，决定还是先回溯一下代码的commit履历，看看是不是有人在函数调用中使用了过大的局部变量，如果是的话，到底用了多大.&lt;/p&gt;

&lt;h3 id=&#34;原因分析-1&#34;&gt;原因分析&lt;/h3&gt;

&lt;p&gt;通过回溯代码的commit, 问题引入的commit很快就被定位到了。但是这个commit的修改内容却和我预想的不太一样：&lt;/p&gt;

&lt;p&gt;引入问题的commit简而言之其实只干了一件事情——它把一个线程的静态&lt;a href=&#34;https://en.wikipedia.org/wiki/Thread-local_storage#C_and_C++&#34;&gt;TLS变量&lt;/a&gt;的大小进行了调整。引发问题的代码概要如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;typedef struct foo {
    char buf_a[BUFFER_SIZE];
    char buf_b[BUFFER_SIZE];
} Foo;

__thread Foo thbuf;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;引入问题的commit的修改就是把上述宏&lt;code&gt;BUFFER_SIZE&lt;/code&gt;的定义从 &lt;strong&gt;512&lt;/strong&gt; 变成了 &lt;strong&gt;4096&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;但是线程的TLS变量大小的改变和线程栈之间又有什么关系呢？&lt;/p&gt;

&lt;p&gt;分析了一下core文件, 突然发现TLS变量的地址只比代码中线程入口函数取到的所谓&amp;rdquo;线程栈基地址&amp;rdquo; 要高一点，但是又没有高出太多——难道这只是一个巧合??&lt;/p&gt;

&lt;p&gt;进一步在网上查找了一下，找到了&lt;a href=&#34;https://www.jianshu.com/p/e01c1a2a46e7&#34;&gt;一篇文章&lt;/a&gt;，里面贴出了一张pthread线程栈的结构图让我恍然大悟:&lt;/p&gt;



&lt;div class=&#34;pure-g&#34;&gt;

  
  
  
  
  &lt;div class=&#34;pure-u-1-1&#34;&gt;
    &lt;div style=&#34;padding: 0 .2em&#34;&gt;
      &lt;img
        class=&#34;pure-img-responsive&#34;
        src=&#34;https://xiaowing.github.io/img/post/20180313/threadstack.jpg&#34;
        alt=&#34;pthread线程栈的结构图&#34;&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  

&lt;/div&gt;


&lt;p&gt;&lt;em&gt;上图出自 &lt;a href=&#34;https://www.jianshu.com/p/e01c1a2a46e7&#34;&gt;https://www.jianshu.com/p/e01c1a2a46e7&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;事实上，我在线程入口函数处取到的所谓&amp;rdquo;栈基址&amp;rdquo;并不是真正的线程栈的栈基址，它只是线程栈中用户程序可用部分的栈底而已。由于TLS变量也是存储在线程栈中的，但是我在算已使用的栈大小时却没有算入TLS变量所占大小。因此，虽然我的防爆栈机制的意图时想让两次栈深检查之间能有16KB的余量可用，但实际上由于计算时的栈基地址选取不当，真正放出的余量并没有16KB，而是要小于16KB。而且随着TLS变量的增大，线程栈阈值之上的余量空间被大大压缩，从而导致在两次栈深检查之间又发生了爆栈。&lt;/p&gt;

&lt;p&gt;TLS变量的增大引发的连锁反应如下所示:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TLS变量大小修改前&lt;/li&gt;
&lt;/ul&gt;



&lt;div class=&#34;pure-g&#34;&gt;

  
  
  
  
  &lt;div class=&#34;pure-u-1-1&#34;&gt;
    &lt;div style=&#34;padding: 0 .2em&#34;&gt;
      &lt;img
        class=&#34;pure-img-responsive&#34;
        src=&#34;https://xiaowing.github.io/img/post/20180313/2st_bursting_before.png&#34;
        alt=&#34;TLS变量修改前的线程栈阈值位置&#34;&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  

&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;TLS变量大小修改后&lt;/li&gt;
&lt;/ul&gt;



&lt;div class=&#34;pure-g&#34;&gt;

  
  
  
  
  &lt;div class=&#34;pure-u-1-1&#34;&gt;
    &lt;div style=&#34;padding: 0 .2em&#34;&gt;
      &lt;img
        class=&#34;pure-img-responsive&#34;
        src=&#34;https://xiaowing.github.io/img/post/20180313/2st_bursting_after.png&#34;
        alt=&#34;TLS变量修改后的线程栈阈值位置&#34;&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  

&lt;/div&gt;


&lt;h3 id=&#34;第二次修正&#34;&gt;第二次修正&lt;/h3&gt;

&lt;p&gt;由于是栈深检查时选取的线程栈基地址有误，因此修改了后台线程入口函数中取基地址的逻辑:&lt;/p&gt;

&lt;p&gt;原本是直接在入口函数一上来便声明一个局部变量并取其地址; 现在修改为使用pthread线程库中的&lt;code&gt;pthread_attr_getstackaddr()&lt;/code&gt;来获取。&lt;/p&gt;

&lt;p&gt;获取当前线程的线程栈基地址以及栈大小的方法可参见下述代码示例:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void *thread_handler(void *args) {
    char start;
    pthread_t self_tid;
    pthread_attr_t curr_attr;
    void *addr = NULL;
    size_t size;

    self_tid = pthread_self();

    if (pthread_getattr_np(self_tid, &amp;amp;curr_attr) != 0)
        perror(&amp;quot;pthread_getattr_np() failed&amp;quot;);
    
    if (pthread_attr_getstackaddr(&amp;amp;curr_attr, &amp;amp;addr) != 0)
        perror(&amp;quot;pthread_attr_getstackaddr() failed&amp;quot;);
    
    if (pthread_attr_getstacksize(&amp;amp;curr_attr, &amp;amp;size) != 0)
        perror(&amp;quot;pthread_attr_getstacksize() failed&amp;quot;);
    
    printf(&amp;quot;[Thread %d]: retrieved address of thread stack %p, stack size %d bytes\n&amp;quot;, (int)self_tid, addr, (int)size);
    
    pthread_attr_destroy(&amp;amp;curr_attr);

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;经过了一波三折，总算是把爆栈防护机制给稳定了。回溯一下整个过程，可以得到以下教训:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;对于程序中所设计的阈值告警，应当把阈值设计得要比&amp;rdquo;不可触及&amp;rdquo;的&lt;strong&gt;红线&lt;/strong&gt;略小，否则阈值告警本身等于无效。&lt;/li&gt;
&lt;li&gt;形而上学地照搬代码并不能真正地解决问题，应当还是要祥日本人提倡的那样&amp;rdquo;&lt;strong&gt;原理原則&lt;/strong&gt;に従って設計する&amp;rdquo;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;最后，我个人认为这个防爆栈实现代码的改善过程还是很有裨益的，因此多写了一点，以飨后者。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>揭秘PG —— 无处不在的OID</title>
      <link>https://xiaowing.github.io/post/20171117_pg_knowhow_oid/</link>
      <pubDate>Fri, 17 Nov 2017 23:08:31 +0800</pubDate>
      
      <guid>https://xiaowing.github.io/post/20171117_pg_knowhow_oid/</guid>
      <description>&lt;p&gt;由于手头当前的工作是基于PostgreSQL(以下简称&lt;strong&gt;PG&lt;/strong&gt;)做二次开发，因此目前对PG的源码也或多或少地读了一些，因此便想到了在博客里分享一些关于阅读PG源码所获得的KnowHow。&lt;/p&gt;

&lt;p&gt;在国内的PG技术圈内，提到PG源码解读自然首推武汉大学的两位彭老师所著的&lt;a href=&#34;https://book.douban.com/subject/6971366/&#34;&gt;《PostgreSQL数据库内核分析》&lt;/a&gt;。不过这本书的着眼点是对PG源码的整体架构，以及SQL引擎，存储系统，事务处理等等这些实现机制&amp;amp;算法的介绍，而我则主要想分享一些PG代码中的一些有意思的小细节/小功能。虽然只是PG那几百万行源码中的沧海一粟，不过从这些小细节中解读程序设计的匠心也是颇有意思的。&lt;/p&gt;



&lt;div class=&#34;pure-g&#34;&gt;

  
  
  
  
  &lt;div class=&#34;pure-u-1-1&#34;&gt;
    &lt;div style=&#34;padding: 0 .2em&#34;&gt;
      &lt;img
        class=&#34;pure-img-responsive&#34;
        src=&#34;https://xiaowing.github.io/img/post/PostgreSQL_logo_120x120.png&#34;
        alt=&#34;PostgreSQL Logo&#34;&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  

&lt;/div&gt;


&lt;p&gt;第一篇就从PG中无处不在的&lt;strong&gt;OID&lt;/strong&gt;开始吧&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;什么是oid&#34;&gt;什么是OID&lt;/h2&gt;

&lt;p&gt;关于PG中OID(&lt;em&gt;Object Identifier&lt;/em&gt;)的概念在&lt;a href=&#34;https://www.postgresql.org/docs/9.6/static/datatype-oid.html&#34;&gt;PostgreSQL官方手册&lt;/a&gt;有比较详细的介绍。简短洁说就是PostgreSQL内部用于标识数据库对象(即通常意义上的&lt;strong&gt;数据表&lt;/strong&gt;，&lt;strong&gt;视图&lt;/strong&gt;，&lt;strong&gt;存储过程&lt;/strong&gt;之类)的一个长度为&lt;strong&gt;4字节&lt;/strong&gt;的标识符。它是PostgreSQL大部分&lt;a href=&#34;https://www.postgresql.org/docs/9.6/static/catalogs.html&#34;&gt;系统表&lt;/a&gt;的主键。PostgreSQL一个为人称道的特点就是其提供了超强的扩展性，用户甚至可以对PostgreSQL的数据类型, 运算符, 存储过程语言进行扩展。而支撑其扩展性的基盘就是&lt;strong&gt;系统表&lt;/strong&gt;和&lt;strong&gt;OID&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;OID在系统表中通常是作为隐藏列存在的，它是以整个PostgreSQL数据库实例(&lt;a href=&#34;https://www.postgresql.org/docs/9.6/static/catalogs.html&#34;&gt;&lt;strong&gt;Database Cluster&lt;/strong&gt;&lt;/a&gt;)的范围内统一分配。在单个系统表内保存的OID一定可以保证OID的唯一性，但是OID不能保证跨系统表之间的唯一性 —— 也就是说，&lt;strong&gt;可以假定&lt;/strong&gt;&amp;ldquo;两个存储过程对象的OID不可能相同&amp;rdquo;; 但是&lt;strong&gt;绝不能假设&lt;/strong&gt;&amp;ldquo;一个表对象的OID肯定不等于一个存储过程对象的OID&amp;rdquo;(尽管在大部分情况下确实不相等)。此外，对于用户定义的数据表，PostgreSQL默认不会为其中的元组分配OID，除非建表时显式指定(其实PostgreSQL并不鼓励用户建表时指定包含OID, 并且不赞成用户的业务逻辑依赖于普通数据表的OID)。&lt;/p&gt;

&lt;p&gt;由于OID是系统表的隐藏列，因此查看系统表中数据库对象的OID时，必须在SELECT语句中显式指定。下图显示了如何查看一个新创建的Database对象的OID:&lt;/p&gt;



&lt;div class=&#34;pure-g&#34;&gt;

  
  
  
  
  &lt;div class=&#34;pure-u-1-1&#34;&gt;
    &lt;div style=&#34;padding: 0 .2em&#34;&gt;
      &lt;img
        class=&#34;pure-img-responsive&#34;
        src=&#34;https://xiaowing.github.io/img/post/20171117/select_oid_sample.png&#34;
        alt=&#34;how to query oid&#34;&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  

&lt;/div&gt;


&lt;p&gt;但是，对于一个使用&lt;code&gt;CREATE TABLE&lt;/code&gt;创建的普通表，PG默认不会为表中的元组保存OID, 自然执行SELECT语句时也无法查到oid这一列。比如下图所示:&lt;/p&gt;



&lt;div class=&#34;pure-g&#34;&gt;

  
  
  
  
  &lt;div class=&#34;pure-u-1-1&#34;&gt;
    &lt;div style=&#34;padding: 0 .2em&#34;&gt;
      &lt;img
        class=&#34;pure-img-responsive&#34;
        src=&#34;https://xiaowing.github.io/img/post/20171117/query_oid_table_withoutoids.png&#34;
        alt=&#34;a table by default&#34;&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  

&lt;/div&gt;


&lt;p&gt;如果希望在向表中插入数据时让PG为每一个元组生成OID，则需要在&lt;code&gt;CREATE TABLE&lt;/code&gt;时显式地加上&lt;code&gt;WITH OIDS&lt;/code&gt;这个属性。如下所示:&lt;/p&gt;



&lt;div class=&#34;pure-g&#34;&gt;

  
  
  
  
  &lt;div class=&#34;pure-u-1-1&#34;&gt;
    &lt;div style=&#34;padding: 0 .2em&#34;&gt;
      &lt;img
        class=&#34;pure-img-responsive&#34;
        src=&#34;https://xiaowing.github.io/img/post/20171117/query_oid_table_withoids.png&#34;
        alt=&#34;a table with oids&#34;&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  

&lt;/div&gt;


&lt;p&gt;&lt;em&gt;需要注意的是，尽管默认情况下PG不会为用户数据表的元组分配OID，但是对于用户创建的每一张表，PG还是会生成一个OID在系统表进行标识&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;oid机制的实现&#34;&gt;OID机制的实现&lt;/h2&gt;

&lt;p&gt;接下来将从以下几个方面聊一聊PG中关于OID机制的实现&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;OID的保存与共享&lt;/li&gt;
&lt;li&gt;OID的分配机制&lt;/li&gt;
&lt;li&gt;OID的持久化&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;oid的保存与共享&#34;&gt;OID的保存与共享&lt;/h3&gt;

&lt;p&gt;众所周知PG是一个多进程架构的数据库，每个用户会话对应了一个postgres进程, 由于受用户的DDL语句/DML语句操作，每一个postgres进程都有可能同时要求分配新的OID; 与此同时实例内部的一些常驻后台进程的动作也可能要求分配新的OID。因此若要实现整个实例范围内的OID统一管理，那么通常首选方案就是&lt;strong&gt;共享内存&lt;/strong&gt;, 事实上PG也是这么做的:&lt;/p&gt;

&lt;p&gt;首先，PG中设计了一个&lt;code&gt;VariableCacheData&lt;/code&gt;结构体来存放OID相关的数据:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;/* include/access/transam.h */
typedef struct VariableCacheData
{
	Oid	nextOid;    /* 保存了下一个要分配的OID */
	uint32 oidCount;    /* 剩余可用的OID个数 */

	TransactionId nextXid;
	TransactionId oldestXid;
	TransactionId xidVacLimit;
	TransactionId xidWarnLimit;
	TransactionId xidStopLimit;
	TransactionId xidWrapLimit;
	Oid	   oldestXidDB;

	TransactionId oldestCommitTsXid;
	TransactionId newestCommitTsXid;

	TransactionId latestCompletedXid;	
} VariableCacheData;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在整个数据库实例的运行期间，只会在实例启动时(也就是Postmaster进程启动时)在共享内存内创建一个&lt;code&gt;VariableCacheData&lt;/code&gt;结构体实例，同时Postmaster进程会将自己的&lt;code&gt;VariableCache&lt;/code&gt;类型(本质上就是VariableCacheData指针)的全局变量&lt;code&gt;ShmemVariableCache&lt;/code&gt;赋值为共享内存中&lt;code&gt;VariableCacheData&lt;/code&gt;结构体的地址。由于在linux上通过&lt;code&gt;fork()&lt;/code&gt;创建子进程时子进程会继承父进程的所有资源——包括全局变量。因此在实例运行过程中，Postmaster的子进程(含所有postgres进程以及其余的常驻后台进程)也就都共享了这个结构体的地址。&lt;/p&gt;

&lt;p&gt;全局变量&lt;code&gt;ShmemVariableCache&lt;/code&gt;的定义以及初始化的代码如下所示:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;变量定义&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;/* backend/access/transam/varsup.c */
...(中略)...
VariableCache ShmemVariableCache = NULL;
...(下略)...
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;初始化&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;/* backend/storage/ipc/shmem.c */
void 
InitShmemAllocation(void) 
{
  ~(中略)~
  ShmemVariableCache = (VariableCache)
		ShmemAlloc(sizeof(*ShmemVariableCache));
  memset(ShmemVariableCache, 0, sizeof(*ShmemVariableCache));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;需要注意的是Windows上的进程模型与Linux不同，Windows上并没有像&lt;code&gt;fork()&lt;/code&gt;这样能使子进程天生继承父进程资源的机制。因此PG在Windows上实现Postmaster进程向子进程传递全局变量&lt;code&gt;ShmemVariableCache&lt;/code&gt;时稍微绕了一下，将相关的地址dump到一个临时文件&amp;rdquo;pgsql_tmp&amp;rdquo;中，然后在调用&lt;code&gt;CreateProcess()&lt;/code&gt;创建子进程时将文件路径传入后再由子进程从文件中将地址恢复出来。这个过程就不在此处赘述了。&lt;/p&gt;

&lt;h3 id=&#34;oid的生成机制&#34;&gt;OID的生成机制&lt;/h3&gt;

&lt;p&gt;当一条元组被INSERT到表中的时候(也包括语法层面的&lt;code&gt;UPDATE&lt;/code&gt;语句，因为PG中的UPDATE本质上是将更新前的旧元组标记为无效并新增元组)。如果这是一张系统表，或是一张在创建时加了&lt;code&gt;WITH OIDS&lt;/code&gt;的用户数据表，那么在写入元组的时候，PG就会申请生成一个新的OID，并写到新元祖的OID字段中，这时就涉及到了OID的生成。&lt;/p&gt;

&lt;p&gt;OID的生成逻辑其实非常简单，其核心算法就是&amp;rdquo;把在保存共享内存的&lt;code&gt;VariableCacheData&lt;/code&gt;结构体中当前的&lt;code&gt;nextoid&lt;/code&gt;分配出去，之后让&lt;code&gt;nextoid&lt;/code&gt;自增一，同时让&lt;code&gt;oidcount&lt;/code&gt;减一&amp;rdquo;。当然，考虑到多个会话的并发，所以在执行上述算法的时候，会加上一把排他锁。&lt;/p&gt;

&lt;p&gt;上述核心算法的代码如下所示:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;/* backend/access/transam/varsup.c */
Oid
GetNewObjectId(void)
{
	Oid			result;

	if (RecoveryInProgress())
		elog(ERROR, &amp;quot;cannot assign OIDs during recovery&amp;quot;);

	LWLockAcquire(OidGenLock, LW_EXCLUSIVE);

	if (ShmemVariableCache-&amp;gt;nextOid &amp;lt; ((Oid) FirstNormalObjectId))
	{
		if (IsPostmasterEnvironment)
		{
			ShmemVariableCache-&amp;gt;nextOid = FirstNormalObjectId;
			ShmemVariableCache-&amp;gt;oidCount = 0;
		}
		else
		{
			if (ShmemVariableCache-&amp;gt;nextOid &amp;lt; ((Oid) FirstBootstrapObjectId))
			{
				ShmemVariableCache-&amp;gt;nextOid = FirstNormalObjectId;
				ShmemVariableCache-&amp;gt;oidCount = 0;
			}
		}
	}

	if (ShmemVariableCache-&amp;gt;oidCount == 0)
	{
		XLogPutNextOid(ShmemVariableCache-&amp;gt;nextOid + VAR_OID_PREFETCH);
		ShmemVariableCache-&amp;gt;oidCount = VAR_OID_PREFETCH;
	}

	result = ShmemVariableCache-&amp;gt;nextOid;

	(ShmemVariableCache-&amp;gt;nextOid)++;
	(ShmemVariableCache-&amp;gt;oidCount)--;

	LWLockRelease(OidGenLock);

	return result;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个简单的分配算法中有几个细节稍加说明一下:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;一开始的对&lt;code&gt;RecoveryInProgress()&lt;/code&gt;的调用，是判断当前实例是否处于恢复状态。我个人认为与其说它是在防护实例的恢复状态下不应存在的写操作，更不如说它是对&lt;strong&gt;Hot standby节点禁写&lt;/strong&gt;原则的又一层防护，毕竟Hot standby节点一直是运行于恢复态的。也就是说，Hot standby节点上的OID只能通过应用xlog来得到。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;在之前的博文&lt;a href=&#34;https://xiaowing.github.io/post/20170903_howto_create_a_postgres_builtin_function/&#34;&gt;如何为PostgreSQL创建一个内置函数？&lt;/a&gt;我曾提到过&lt;strong&gt;16384&lt;/strong&gt;这个OID，事实上这也正是PG实例的Bootstrap过程结束后第一个留给用户的OID。因此，当OID递增耗尽回卷时，回卷后的第一个OID不是0，而是16384(也就是上述代码中的&lt;code&gt;FirstNormalObjectId&lt;/code&gt;)。这样可以确保PG实例内的所有&lt;strong&gt;内置数据库对象&lt;/strong&gt;的OID是绝对唯一的。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;从上述代码可知，OID在每分配8192(即代码中的宏&lt;code&gt;VAR_OID_PREFETCH&lt;/code&gt;)个之后便会向xlog中记一条关于下一个OID分配区间的最大值。这个设计的意图会在下一章节介绍，此处暂时略过。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;但是，由于OID只有四个字节，因此可以预见到它会有溢出的时刻，这时就会产生上文的所说的回卷逻辑。当OID回卷时，如何保证OID的相对唯一性(这里的“唯一性”在“什么是OID”这一章中有说明)呢？PG中实际上是在上述&lt;code&gt;GetNewObjectId()&lt;/code&gt;之外又封装了一个&lt;code&gt;GetNewOid()&lt;/code&gt;接口供PG代码使用，而在这个接口实现中，PG通过OID字段的索引实现了OID在一张表内的唯一性:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;/* backend/catalog/catalog.c */
Oid
GetNewOid(Relation relation)
{
	Oid			oidIndex;

	Assert(relation-&amp;gt;rd_rel-&amp;gt;relhasoids);

	if (IsBootstrapProcessingMode())
		return GetNewObjectId();

	oidIndex = RelationGetOidIndex(relation);

	if (!OidIsValid(oidIndex))
	{
		if (IsSystemRelation(relation))
			elog(WARNING, &amp;quot;generating possibly-non-unique OID for \&amp;quot;%s\&amp;quot;&amp;quot;,
				 RelationGetRelationName(relation));
		return GetNewObjectId();
	}

	return GetNewOidWithIndex(relation, oidIndex, ObjectIdAttributeNumber);
}

Oid
GetNewOidWithIndex(Relation relation, Oid indexId, AttrNumber oidcolumn)
{
	Oid			newOid;
	SnapshotData SnapshotDirty;
	SysScanDesc scan;
	ScanKeyData key;
	bool		collides;

	Assert(!IsBinaryUpgrade || RelationGetRelid(relation) != TypeRelationId);

	InitDirtySnapshot(SnapshotDirty);

	do
	{
		CHECK_FOR_INTERRUPTS();
		newOid = GetNewObjectId();
		ScanKeyInit(&amp;amp;key, oidcolumn, BTEqualStrategyNumber, F_OIDEQ,
					ObjectIdGetDatum(newOid));
		scan = systable_beginscan(relation, indexId, true, &amp;amp;SnapshotDirty, 1, &amp;amp;key);
		collides = HeapTupleIsValid(systable_getnext(scan));
		systable_endscan(scan);
	} while (collides);

	return newOid;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其实它的思路也很简单: 如果这张表上没有基于OID字段的索引(理论上这种情况不会发生在系统表上，只会在用户的数据表上)，那么就直接调用上述核心算法的&lt;code&gt;GetNewObjectId()&lt;/code&gt;直接生成一个OID; 如果表上存在基于OID字段的索引，那么就反复尝试调用&lt;code&gt;GetNewObjectId()&lt;/code&gt;直到生成了一个这张表中未曾出现过的OID.此时生成的OID尽管可以保证在目标表中唯一，但很有可能它已经在别的表中也已经被使用了。这就是为什么在第一章中会说“&lt;strong&gt;在单个系统表内保存的OID一定可以保证唯一性，但是OID不能保证跨系统表之间的唯一性&lt;/strong&gt;”&lt;/p&gt;

&lt;h3 id=&#34;oid的持久化&#34;&gt;OID的持久化&lt;/h3&gt;

&lt;p&gt;搞清楚了OID的生成机制，很自然地就会产生一个想法: 既然每生成一个OID都会加锁，那么在上述的OID唯一性确保逻辑中如果尝试生成OID的次数过多，那就肯定会对并发的性能造成较大的伤害。但OID又是一个保存在共享内存中的数据，假设每次实例正常停机/重启或者异常Crash后恢复，OID就又要从初始的16384开始重新递增，结合上述生成逻辑中确保表内唯一性的试错循环，这对性能将是一个灾难!&lt;/p&gt;

&lt;p&gt;还好，PG的开发者们也想到了这一层, 而上述悲惨情况之所以不会发生的原因是因为PG中对于共享内存中的&lt;code&gt;newoid&lt;/code&gt;进行了持久化以确保实例重启后或者恢复后，还能够接着之前的&lt;code&gt;newoid&lt;/code&gt;生成，而不是从头再来一遍。&lt;/p&gt;

&lt;h3 id=&#34;持久化的时机&#34;&gt;持久化的时机&lt;/h3&gt;

&lt;p&gt;PG对于&lt;code&gt;newoid&lt;/code&gt;的持久化有两处：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;时机1: 上文的OID核心生成算法中所述——每分配完8192个OID就向xlog中插入一条记录，将下一个8192分配区间的最大值记录在xlog中。&lt;/p&gt;

&lt;p&gt;这里需要注意两点：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;PG并不是每生成一个OID就向xlog中记录一次。理由是虽然这样很保险，但是记录xlog(就算只是写缓冲区)也是会对性能带来负面影响。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;写在xlog中的不是当前已分配区间的最大OID，而是下一个分配区间的最大OID。这样一来它可以保证在这个分配区间结束之前，所有已落入磁盘上的元组中，没有一个OID会大于这个写入xlog记录的OID(OID发生回卷除外&amp;hellip;&amp;hellip;)。这个设计意图在接下来介绍oid的恢复机制时会解说其用意。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;时机2: 生成Checkpoint时, 按下述逻辑将oid数据写入PG实例控制文件的检查点信息中.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void
CreateCheckPoint(int flags)
{
    ~(前略)~

    CheckPoint  checkPoint;
    MemSet(&amp;amp;checkPoint, 0, sizeof(checkPoint));
    checkPoint.time = (pg_time_t) time(NULL);

    ~(中略)~
        
    LWLockAcquire(OidGenLock, LW_SHARED);
    checkPoint.nextOid = ShmemVariableCache-&amp;gt;nextOid;
    if (!shutdown)
        checkPoint.nextOid += ShmemVariableCache-&amp;gt;oidCount;
    LWLockRelease(OidGenLock);

    ~(后略)~
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;有意思的是，记录在Checkpoint时会根据Checkpoint的种类来执行不一样的记录行为:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;如果是SHUTDOWN检查点，则记录真实的下一个待分配的OID&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果不是SHUTDOWN检查点，则记录的其实和记录在xlog中的类似：当前分配区间的最大值。理由也是相仿的: 确保当前时间点已落入磁盘的元组中的已生成OID没有大于记录在checkpoint信息中的OID。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;两个持久化位置几乎殊途同归，持久化OID的策略几乎相同，这应该不是巧合:)&lt;/p&gt;

&lt;h3 id=&#34;恢复机制&#34;&gt;恢复机制&lt;/h3&gt;

&lt;p&gt;接下来从PG的恢复机制来揭晓上述持久化的残留疑问。&lt;/p&gt;

&lt;p&gt;PG从xlog恢复数据时一定是从最近的Checkpoint开始恢复，因为已实施的Checkpoint可以保证到这个Checkpoint为止的数据变更都已经落盘，且已利用xlog进行了一致性确认。所以PG只需要从这个最近的Checkpoint之后的xlog开始恢复即可。 所以，我们可以将全局的&lt;code&gt;VariableCacheData&lt;/code&gt;结构体中的&lt;code&gt;newOid&lt;/code&gt;字段的恢复分成以下几种情况：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;最近的Checkpoint之后没有记录NewOid的xlog记录&lt;/p&gt;

&lt;p&gt;这说明，实例Crash掉的时间点到最近的Checkpoint之间的时间间隔内，Oid的生成还在同一个8192的分配区间内。这时，即便Checkpoint之后还有一些新的数据写入，但是由于Checkpoint信息中持久化的是当前OID分配区间的最大值，因此可以确保Checkpoint之后分配的OID没有一个能够超过被持久化的那个OID。因此将全局的&lt;code&gt;VariableCacheData&lt;/code&gt;结构体中的&lt;code&gt;newOid&lt;/code&gt;字段恢复成当前分配期间的最大值，后续再生成新的OID也不用经历生成逻辑中确保表内唯一性的试错循环。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;最近的Checkpoint之后存在一条或多条记录NewOid的xlog记录&lt;/p&gt;

&lt;p&gt;这说明，实例Crash掉的时间点到最近的Checkpoint之间，OID的生成已经跨越了多个8192的分配区间。不过，由于xlog中记录NewOid时记录的都是每一个OID分配区间的最大值。与上一个情况相似，在逐个应用每一条记录NewOid的xlog日志记录后，最终会将将全局的&lt;code&gt;VariableCacheData&lt;/code&gt;结构体中的&lt;code&gt;newOid&lt;/code&gt;字段恢复成最后一个被使用的OID分配区间的最大值，仍然可以保证后续再生成新的OID也不用经历生成逻辑中确保表内唯一性的试错循环。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;当然，这两种情况都是建立在OID尚未发生回卷的前提下才有实际意义。如果已经发生了回卷，&lt;code&gt;newOid&lt;/code&gt;恢复的其实是一个较小的值，那么试错循环应该就不可避免了。&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;最后一种情况，最近的一个Checkpoint是SHUTDOWN检查点.&lt;/p&gt;

&lt;p&gt;这就意味着实例是被正常关闭重启的, 那么自然这个Checkpoint之后当然不会有任何新的xlog，也自然不会有任何磁盘上的数据更新。因此此时恢复的就是关机Checkpoint时真实的下一个待分配的OID。实例重启后从这个OID开始继续递增即可。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;由此可见，为了让PG实例启动/恢复后生成新的OID时能够尽可能减少保证唯一性的试错循环带来的负面影响。PG基于已有的恢复机制设计了一套比较合理又巧妙的持久化机制。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;上述恢复逻辑写在了&lt;code&gt;backend/access/transam/xlog.c&lt;/code&gt;的&lt;code&gt;
xlog_redo()&lt;/code&gt;函数和&lt;code&gt;StartupXlog()&lt;/code&gt;函数中，由于代码较多便不再贴出。&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;关于oid的一些思考&#34;&gt;关于OID的一些思考&lt;/h2&gt;

&lt;p&gt;关于OID本身的规格以及机制的介绍，基本上就到此结束了。OID的存在，实际上为PG内部的数据库对象实现了一个统一的抽象接口，进而PG可以实现其引以自豪的强大扩展能力。不过，站在&amp;rdquo;事后诸葛亮&amp;rdquo;的角度，我们还是可以看出OID设计中的一些遗憾。&lt;/p&gt;

&lt;p&gt;最大的遗憾恐怕是把OID设计得有点短了: 4个字节对于今天的大数据时代而言，很容易就耗尽了。而且在上文中也说过，一旦4个字节单调递增结束进入回卷阶段，那么将有可能会给PG的性能带来较大的负面影响。&lt;/p&gt;

&lt;p&gt;其实从上述OID的实现代码我们可以合理推测: 一开始的设计初衷中，OID肯定是希望被用来对PG中的所有数据库对象(包括用户数据表中的元组)进行唯一性标识的。佐证有两点：一来是OID的生成机制是简单递增; 二来是到&lt;a href=&#34;https://www.postgresql.org/docs/8.0/static/datatype-oid.html&#34;&gt;PG 8.0为止的手册&lt;/a&gt;里，用户&lt;code&gt;CREATE TABLE&lt;/code&gt;创建的数据表的默认行为是会给所有插入元组附上OID。当然，站在今天这个时间点上，唯一标识实例中所有数据库对象的重任肯定是没法儿交给OID来完成，因此OID就变成了系统表的专属“玩物”了。&lt;/p&gt;

&lt;p&gt;这个遗憾，恐怕可以比肩当年比尔盖茨的“内存有640KB就够了”的预言以及即将枯竭的IPv4地址资源。&lt;/p&gt;

&lt;p&gt;最后，再发散性地想一想: OID本身就是为了实现一个自增的唯一性ID。如果扩展到分布式系统架构下，PG的OID实现是否也可以套用呢？ 答案是肯定的，只需要把上述OID的实现机制中的两部分替换掉，我们就可以用完全相同的逻辑来实现一个适用于分布式架构下的高可用自增唯一性ID的生成服务。而那需要替换掉的两部分分别是:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;将&lt;strong&gt;共享内存&lt;/strong&gt;替换为一个高可用的内存数据库(比如&lt;strong&gt;Redis&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;将&lt;strong&gt;单机上的磁盘&lt;/strong&gt;替换为一个高可用的持久化存储组件(比如&lt;strong&gt;一个DBMS&lt;/strong&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;昨天看到的这篇文章&lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzI0MTk0NTY5MA==&amp;amp;mid=2247483753&amp;amp;idx=1&amp;amp;sn=ee92dd4b76550d333047256ed331b80a&amp;amp;chksm=e9029c5cde75154a56d76e8608d317ba49a073cd090db610992b2a0c35d2c649819635ae95e7&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=1208dDQ4MjIHoXZbH7xYZspA&amp;amp;pass_ticket=WMTOs1AURvSB6mWmq5lLAwcyI9EAIL%2BZRa4v13AlE82VEpLG7zmt4Y2JIEYG2J9E#rd&#34;&gt;基于 Redis 的序列号服务的设计&lt;/a&gt;则基本上验证了我的上述想法。难怪&lt;a href=&#34;https://coolshell.cn/haoel&#34;&gt;陈皓&lt;/a&gt;在不同场合都一直在劝诫程序员:&lt;strong&gt;&amp;ldquo;基础上的东西的变化少，基础上的东西一通百通&amp;rdquo;&lt;/strong&gt;。果然如是!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>主线程等待子线程结束的各语言实现</title>
      <link>https://xiaowing.github.io/post/20170805_main_thread_sync_with_others/</link>
      <pubDate>Sat, 05 Aug 2017 22:18:06 +0800</pubDate>
      
      <guid>https://xiaowing.github.io/post/20170805_main_thread_sync_with_others/</guid>
      <description>&lt;p&gt;在涉及到并发编程的情况下，经常性地会碰到一种场景:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;由一个线程开启了多个线程并发执行多个任务，之后由该线程(so called &amp;ldquo;主线程&amp;rdquo;)等待多个线程都结束后汇总结果.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这种场景下，主线程在其创建的子线程执行期间内需要阻塞，直到其他子线程都执行完毕。由于这类场景已经在不同语言的开发中遇到多次，所以汇总一下这些语言的常用实现方法，以后查起来也方便~&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;C语言实现
C语言在操作多线程方便由于缺乏一个统一的标准库，所以在Linux和Windows上各有各的实现方法:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Linux版实现&lt;/p&gt;

&lt;p&gt;在Linux上的实现，主要是基于POSIX thread库进行实现，实例代码如下:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;pthread.h&amp;gt;

int main(void) {
    int i;
    pthread_t threads[THREAD_NUM];

    pthread_setconcurrency(THREAD_NUM);

    for (i = 0; i &amp;lt; THREAD_NUM; i++){
        /* 将需要执行的job的函数地址func传入新建的子线程 */
        pthread_create(&amp;amp;threads[i], NULL, func, NULL);
    }

    for(i = 0; i &amp;lt; THREAD_NUM; i++){
        pthread_join(handles[i], NULL);
    }

    /* 后续的处理逻辑略... */
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Windows版实现&lt;/p&gt;

&lt;p&gt;在Windows版上的实现中，主要是基于Windows API实现。由于Windows本身就和Linux就是风格迥异，因此在阻塞主线程的API设计上，也是略有不同：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;Windows.h&amp;gt;

int main(void) {
    int i;
    HANDLE handles[THREAD_NUM];

    for (i = 0; i &amp;lt; THREAD_NUM; i++){
        /* 将需要执行的job的函数地址func传入新建的子线程 */
        handles[i] = CreateThread(NULL, 0, func, NULL, 0, NULL);
    }

    WaitForMultipleObjects(THREAD_NUM, handles, TRUE, INFINITE);

    /* 后续的处理逻辑略... */
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;需要注意的是，Windows API的&lt;code&gt;WaitForMultipleObjects()&lt;/code&gt;其实不仅仅是为多线程场景服务的，它可以用与多种内核句柄，如&lt;code&gt;Event&lt;/code&gt;，&lt;code&gt;Mutex&lt;/code&gt;，&lt;code&gt;Process&lt;/code&gt;，&lt;code&gt;Thread&lt;/code&gt;，&lt;code&gt;Semaphore&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Python3的实现&lt;/p&gt;

&lt;p&gt;Python3的实现形式与C语言的Linux版类似: 当子线程仍活着的时候，则通过类似Join()方法之类的API来阻塞当前的主线程。代码示例如下:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from threading import Thread

if __name__ == &#39;__main__&#39;:
    thread_list = []

    for x range (0, THREAD_NUM):
        # 将需要执行的job的函数和参数传入新建的子线程
        t = Thread(target=job_func, args=(job_args,))
        t.start()
        thread_list.append(t)
        
    for element in thread_list:
        if element.is_alive():
            element.join()    # 通过join方法阻塞主线程
    else:
        # 后续的处理逻辑略...
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Golang的实现&lt;/p&gt;

&lt;p&gt;由于Golang的语言特色，并发通过goroutine来实现。通常情况下，各个goroutine根本不需要知道彼此的存在。因此对于这个场景的实现方式，与之前的那些语言都有所不同.代码示例如下:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main
    
import (
    &amp;quot;sync&amp;quot;
)

func main() {
    var wait sync.WaitGroup
    wait.Add(ROUTINE_NUM)

    for i := 0; i &amp;lt; ROUTINE_NUM; i++ {
        go func() {
            defer wait.Done()

            //Goroutine所要执行的Job逻辑略...
        }()
    }
    wait.Wait()

    // 后续的处理逻辑略...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在之前的语言中，主线程在起了多个子线程后，不管用什么API阻塞，主线程或多或少还需要关注一下子线程(句柄等)，但是在Golang中，主协程不需要关注各个携程。主协程等待其他协程的这个场景，完全基于Workgroup就可以简单实现。&lt;/p&gt;

&lt;p&gt;真不愧是一门面向并发的语言:)&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;最后需要说明的是，虽然本文描述的这个场景叫做&amp;rdquo;主线程等待子线程&amp;rdquo;。但实际上，无论是线程模型还是协程模型，线程与线程之间(协程与协程之间)都是平等的。毕竟只有在多进程模型下，被fork出的子进程会继承父进程的大部分数据(如打开的文件描述符)，完全相当于父进程的副本的形式。而这样的关系在线程模型(或协程模型)中并不存在，此处的说法完全只是遵循某种不成文的惯例，算是&amp;rdquo;&lt;strong&gt;阀值&lt;/strong&gt;&amp;ldquo;之于&amp;rdquo;&lt;strong&gt;阈值&lt;/strong&gt;&amp;ldquo;这样的错误吧。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>